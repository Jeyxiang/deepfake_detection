{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake detection using Deep learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. installing and importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install tensorflow\n",
    "# %pip install matplotlib\n",
    "# %pip install scipy\n",
    "# %pip install keras-tuner\n",
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\School work\\University Y3\\BT4240_CS4487\\PROJECT\\.venv\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import zipfile\n",
    "import fnmatch\n",
    "import os.path\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.layers import Dense, Flatten, AveragePooling2D\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "from sklearn import metrics\n",
    "# from sklearn import datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the version and python bits is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Python Version- 3.7.8\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow might not be able to be installed under different python versions\n",
    "from platform import python_version\n",
    "print(\"Current Python Version-\", python_version())\n",
    "\n",
    "\n",
    "# python 64 bits required\n",
    "import struct\n",
    "print(struct.calcsize(\"P\") * 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating file directories, extract image into respective directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "# ├── Test  \n",
    "# │   ├── manipulated\n",
    "# │   └── original\n",
    "# ├── Training\n",
    "# │   ├── manipulated \n",
    "# │   └── original\n",
    "# └── Validation\n",
    "#     ├── manipulated \n",
    "#     └── original\n",
    "\n",
    "# Creates the appropriate directory structures for training, validation and test sets.\n",
    "try:\n",
    "  shutil.rmtree('./Split Data')      \n",
    "except:\n",
    "  pass                #Split Data didn't exist\n",
    "     \n",
    "os.mkdir('./Split Data')\n",
    "cdf={\"Training\":0.7,\"Validation\":0.85,\"Test\":1} #OBS! Has to be increment percentages of 5 to make batch size fit\n",
    "for dir in list(cdf.keys()):\n",
    "    os.mkdir('./Split Data/{}'.format(dir))\n",
    "    os.mkdir('./Split Data/{}/manipulated'.format(dir))\n",
    "    os.mkdir('./Split Data/{}/original'.format(dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which assigns the file to the correct directory based on the discrete cumulative distribution function cdf\n",
    "\n",
    "def assign_data(cdf):\n",
    "    nbr=random.random()\n",
    "    for set in list(cdf.keys()):\n",
    "        if nbr<cdf[set]:\n",
    "            return set\n",
    "\n",
    "dist={\"Training\":0,\"Validation\":0,\"Test\":0}\n",
    "filename = 'data.zip'\n",
    "zfile = zipfile.ZipFile(filename, 'r')\n",
    "counter=0\n",
    "samplesize=12000\n",
    "# Each file is loaded in sequence and randomly assigned to the corresponding directory \n",
    "# in the new straucture according to cdf. Dictionary dist keeps track of number of each set.\n",
    "for name in zfile.namelist():\n",
    "    save_path = './Split Data/'\n",
    "    name_of_file=\"\"\n",
    "    label=\"\"\n",
    "    if fnmatch.fnmatch(name, \"data/manipulated/*.png\"):\n",
    "        name_of_file=name[len(\"data/manipulated/\"):]\n",
    "        label=\"manipulated\"\n",
    "    elif fnmatch.fnmatch(name,\"data/original/*.png\"):\n",
    "        name_of_file=name[len(\"data/original/\"):]\n",
    "        label=\"original\"\n",
    "    if name_of_file != \"\":\n",
    "        myfile = zfile.open(name)\n",
    "        img = matplotlib.image.imread(myfile)\n",
    "        rand_assign=assign_data(cdf)\n",
    "        dist[rand_assign]+=1\n",
    "        save_path+=rand_assign+\"/\"+label # eg. \"Split Data/Training/manipulated\n",
    "        completeName = os.path.join(save_path, name_of_file)         \n",
    "        matplotlib.image.imsave(completeName,img)\n",
    "        counter+=1\n",
    "        if counter>=samplesize:     \n",
    "            break\n",
    "\n",
    "zfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for checking the set sizes\n",
    "for fr in list(dist.keys()):\n",
    "    for label in [\"manipulated\",\"original\"]:\n",
    "        print(\"Size of {}/{}: {}\".format(fr,label,len(os.listdir(os.path.join('./Split Data',fr,label)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building the model by initialising the attributes, layers etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A batch size of 32 means that 32 samples from the training dataset will be used to estimate the error gradient before the model weights are updated. \n",
    "- One training epoch means that the learning algorithm has made one pass through the training dataset, where examples were separated into randomly \n",
    "selected “batch size” groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant fields\n",
    "BATCH_SIZE= 64 \n",
    "imgsize=(299,299)\n",
    "COUNT_DENSE = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 1s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 2048)              21802784  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,806,888\n",
      "Trainable params: 21,772,456\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building inception Model\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax',\n",
    "    pooling='avg'\n",
    "))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation = 'relu'))\n",
    "model.add(Dense(2,activation='softmax'))  \n",
    "model.layers[0].trainable = True    # train all the layers\n",
    "model.summary()\n",
    "#optimizer = optimizers.SGD(learning_rate = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True) \n",
    "optimizer1 = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,amsgrad=False,name=\"Adam\")\n",
    "model.compile(optimizer = optimizer1, loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])   #Loss function arbitrary now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8403 images belonging to 2 classes.\n",
      "Found 1812 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet_v2 import preprocess_input\n",
    "\n",
    "trainpath=os.path.join(\"./Split Data\", \"Training\")\n",
    "valpath=os.path.join(\"./Split Data\", \"Validation\")\n",
    "\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_gen=train_datagen.flow_from_directory(trainpath, target_size=imgsize, batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
    "val_gen=train_datagen.flow_from_directory(valpath, target_size=imgsize, batch_size=BATCH_SIZE, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialising callbacks, stoppers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- monitor – This allows us to specify the performance measure to monitor in order to end training.\n",
    "\n",
    "- mode – It is used to specify whether the objective of the chosen metric is to increase maximize or to minimize.\n",
    "\n",
    "- verbose – To discover the training epoch on which training was stopped, the “verbose” argument can be set to 1. Once stopped, the callback will print the epoch number.\n",
    "\n",
    "- patience – The first sign of no further improvement may not be the best time to stop training. This is because the model may coast into a plateau of no improvement or even get slightly worse before getting much better. We can account for this by adding a delay to the trigger in terms of the number of epochs on which we would like to see no improvement. This can be done by setting the “patience” argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  os.mkdir(os.path.join('.','Working Model'))       \n",
    "except:\n",
    "  pass                #Working Model aleardy exists\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "\n",
    "cb_checkpointer = ModelCheckpoint(filepath =os.path.join(\".\",\"Working Model\",\"best.hdf5\") , monitor = 'val_loss', save_best_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 169 50 37\n"
     ]
    }
   ],
   "source": [
    "#Just for double checking\n",
    "print(BATCH_SIZE, len(train_gen), BATCH_SIZE, len(val_gen))\n",
    "\n",
    "\n",
    "\n",
    "# os.mkdir(os.path.join('.','Working Model'))         used to create the Working Model directory\n",
    "# TRAIN_STEPS=int(len(train_gen)/EPOCHS)\n",
    "# VAL_STEPS=len(val_gen)\n",
    "# print(\"EPOCHS: {}, TRAINING STEPS: {}, VAL STEPS: {}\".format(EPOCHS, TRAIN_STEPS, VAL_STEPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fitting, training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=20\n",
    "fit_history = model.fit_generator(\n",
    "        train_gen,\n",
    "        epochs = EPOCHS,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training & validation error and loss function over epochs\n",
    "plt.figure(1, figsize = (15,8)) \n",
    "    \n",
    "plt.subplot(221)  \n",
    "plt.plot(fit_history.history['accuracy'])  \n",
    "plt.plot(fit_history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "    \n",
    "plt.subplot(222)  \n",
    "plt.plot(fit_history.history['loss'])  \n",
    "plt.plot(fit_history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing the trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_path):\n",
    "  # fields required\n",
    "  Accuracy, Recall, Precision, AUC = 0, 0, 0, 0\n",
    "\n",
    "  # init constants  \n",
    "  BATCH_SIZE=64\n",
    "  imgsize=(299,299)\n",
    "\n",
    "  # Model used\n",
    "  built_model=Sequential()\n",
    "  built_model.add(InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax',\n",
    "    pooling='avg'\n",
    "    ))\n",
    "\n",
    "  built_model.add(Flatten())\n",
    "  built_model.add(Dense(2, activation = 'relu'))\n",
    "  built_model.add(Dense(2,activation='softmax'))  \n",
    "  built_model.layers[0].trainable = True    \n",
    "  built_model.summary()\n",
    "  optimizer1 = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,amsgrad=False,name=\"Adam\")\n",
    "  built_model.compile(optimizer = optimizer1, loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])  \n",
    "\n",
    "  test_img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "  test_generator=test_img_gen.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    target_size = imgsize,\n",
    "    batch_size = BATCH_SIZE,   \n",
    "    class_mode = None,    \n",
    "    shuffle = False,      \n",
    "    seed = 123            \n",
    "    )\n",
    "  \n",
    "  built_model.load_weights(model)\n",
    "  print(\"model loaded\")\n",
    "\n",
    "  predicted = built_model.predict(test_generator,steps = len(test_generator), verbose = 1)\n",
    "  predicted_class_indices = np.argmax(predicted, axis = 1)\n",
    "\n",
    "  y = test_generator.classes\n",
    "  Accuracy = metrics.accuracy_score(y,predicted_class_indices)\n",
    "  print(\"Model Accuracy: \", Accuracy)\n",
    "\n",
    "  Precision = metrics.precision_score(y, predicted_class_indices, average='binary')\n",
    "  print(\"Model Precision: \", Precision)\n",
    "\n",
    "  Recall = metrics.recall_score(y, predicted_class_indices, average='binary')\n",
    "  print(\"Model Recall: \", Recall)\n",
    "\n",
    "  AUC = metrics.roc_auc_score(y, predicted_class_indices)\n",
    "  print(\"AUC: \", AUC)\n",
    "\n",
    "  filenames = [i.split('\\\\')[1] for i in test_generator.filenames] \n",
    "  actualLabel = [i.split('\\\\')[0] for i in test_generator.filenames]\n",
    "  for i in range(len(actualLabel)):\n",
    "    if actualLabel[i] == 'manipulated':\n",
    "        actualLabel[i] = '0'\n",
    "    else:\n",
    "        actualLabel[i]  = '1' \n",
    "  results_df = pd.DataFrame(\n",
    "    {\n",
    "        'id': pd.Series(filenames), \n",
    "        'actual label': pd.Series(actualLabel),\n",
    "        'pred label': pd.Series(predicted_class_indices)\n",
    "    }\n",
    "  )\n",
    "  os.makedirs('Result', exist_ok=True)\n",
    "  results_df.to_csv('Result/out.csv')\n",
    "\n",
    "  return Accuracy, Recall, Precision, AUC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Split Data\\\\Test'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path=os.path.join(\"./Split Data\", \"Test\")\n",
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\Working Model\\\\final.hdf5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = os.path.join(\".\",\"Working Model\",\"final.hdf5\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inception_v3 (Functional)   (None, 2048)              21802784  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 4098      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,806,888\n",
      "Trainable params: 21,772,456\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "Found 1785 images belonging to 2 classes.\n",
      "model loaded\n",
      "28/28 [==============================] - 170s 6s/step\n",
      "Model Accuracy:  0.9876750700280112\n",
      "Model Precision:  0.9862542955326461\n",
      "Model Recall:  0.9761904761904762\n",
      "AUC:  0.9847535505430243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9876750700280112,\n",
       " 0.9761904761904762,\n",
       " 0.9862542955326461,\n",
       " 0.9847535505430243)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model,test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40a03b7b172bd2197b5b405d58bfc55505d4cc82ebca9376d27bab8203000ac3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
